{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fV5t7ZHGUVYi",
        "outputId": "2eb7df48-a8b6-447d-a6e3-5949d9805bc5"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.52.2-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting jiter<1,>=0.4.0 (from openai)\n",
            "  Downloading jiter-0.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.9.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.6-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.23.4)\n",
            "Downloading openai-1.52.2-py3-none-any.whl (386 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m386.9/386.9 kB\u001b[0m \u001b[31m28.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx-0.27.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.6-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.0/78.0 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jiter-0.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (325 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m325.2/325.2 kB\u001b[0m \u001b[31m29.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: jiter, h11, httpcore, httpx, openai\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.6 httpx-0.27.2 jiter-0.6.1 openai-1.52.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FOGtwt_EUToP",
        "outputId": "8994e165-c862-45cf-bb16-2e64ad6bc05a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                             prompts\n",
            "0              a vibrant red apple on a wooden table\n",
            "1    a majestic white swan floating on a serene lake\n",
            "2          a sleek black cat sitting on a windowsill\n",
            "3  a delicate glass vase filled with colorful flo...\n",
            "4    a vintage leather suitcase with travel stickers\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "from openai import OpenAI\n",
        "from google.colab import userdata\n",
        "import os\n",
        "import ast\n",
        "\n",
        "\n",
        "os.environ['OPENAI_API_KEY']=userdata.get('Open_AI_key')\n",
        "\n",
        "# Check if cuda is available\n",
        "use_cuda = torch.cuda.is_available()\n",
        "# Set proper device based on cuda availability\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "\n",
        "csv_dir = \"/content/drive/MyDrive/class_proj/\"\n",
        "\n",
        "client = OpenAI()\n",
        "num_prompts = 50\n",
        "num_loops = 200\n",
        "prompts = []\n",
        "for i in range(num_loops):\n",
        "  try:\n",
        "    completion = client.chat.completions.create(\n",
        "        model=\"gpt-4o-mini\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are an AI assistant who is an expert at generating interesting prompts \\\n",
        "                                      which are used to generate images using stable diffusion that have only a single object of interest. \\\n",
        "                                      These images are eventually going to be used to generate 3D images, so it is important that only a single object \\\n",
        "                                      exists in each image. Also, the object should be forward facing. Objects can be living things, or inanimate objects. \\\n",
        "                                      Please output the prompts as a nested python list. The format must be [[\\\"prompt1\\\"], [\\\"prompt2\\\"],..., [\\\"promptN\\\"]] \\\n",
        "                                      Do not add anything else to your response so it can be parsed easily for Python code. \\\n",
        "                                      A comma must be after each part of your reply so it can be treated as a list.\"},\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": f\"Please generate {num_prompts} prompts for use with stable diffusion to provide 2D images as a base to generate 3d images.\"\n",
        "            }\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    response = completion.choices[0].message\n",
        "    response = ast.literal_eval(response.content)\n",
        "    for prompt in response:\n",
        "      prompts.append(prompt)\n",
        "  except:\n",
        "    print('error')\n",
        "    continue\n",
        "prompt_df = pd.DataFrame(prompts, columns=['prompts'])\n",
        "print(prompt_df.head())\n",
        "prompt_df.to_csv(csv_dir + 'prompts.csv')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Used to concat because prompt lists were short due to errors\n",
        "\n",
        "df1 = pd.read_csv('/content/drive/MyDrive/class_proj/prompts.csv', index_col=0)\n",
        "df2 = pd.read_csv('/content/drive/MyDrive/class_proj/prompts2.csv', index_col=0)\n",
        "df3 = pd.read_csv('/content/drive/MyDrive/class_proj/prompts3.csv', index_col=0)\n",
        "df2 = df2.rename(columns={'0': 'prompts'})\n",
        "prompt_final = pd.concat([df1, df2, df3 ], axis=0)\n",
        "print(prompt_final.head())\n",
        "prompt_final.reset_index(inplace=True, drop=True)\n",
        "prompt_final.to_csv(csv_dir + 'prompts_final.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SNAOkgDxpj2I",
        "outputId": "514dae73-6a53-480c-8055-ae0acdf4f4e4"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                     prompts\n",
            "0     a sleek red sports car, forward facing\n",
            "1          a vibrant peacock, forward facing\n",
            "2        a majestic elephant, forward facing\n",
            "3     a classic wooden chair, forward facing\n",
            "4  a shiny silver wristwatch, forward facing\n"
          ]
        }
      ]
    }
  ]
}