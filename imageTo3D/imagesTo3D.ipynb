{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "collapsed_sections": [
        "mBgHX1c_uYcC"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Init code"
      ],
      "metadata": {
        "id": "AwCWRM4at004"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "# Clone the repository\n",
        "!git clone https://github.com/szymanowiczs/splatter-image.git"
      ],
      "metadata": {
        "id": "UPMqr24RzUTH"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Change directory to the cloned repo\n",
        "%cd splatter-image"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i5Ucj4XLzy2_",
        "outputId": "19c22088-666c-4c74-cfcc-f79798687f38"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/splatter-image\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install -r requirements.txt\n",
        "!pip install rembg\n",
        "!pip install omegaconf"
      ],
      "metadata": {
        "id": "GpMMn_GLz1qb"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!git clone https://github.com/graphdeco-inria/diff-gaussian-rasterization"
      ],
      "metadata": {
        "id": "w_-KAzpfPPOi"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd diff-gaussian-rasterization"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5A_1iyKNN4VD",
        "outputId": "1fcb8b43-4730-4c42-a2a9-08f4d441cfa5"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/splatter-image/diff-gaussian-rasterization\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!apt-get install -y libglm-dev"
      ],
      "metadata": {
        "id": "ltFCMLVWIIdr"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!python setup.py build_ext --inplace"
      ],
      "metadata": {
        "id": "7v04y2xAH0kx"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('/content/splatter-image')\n",
        "sys.path.append('diff-gaussian-rasterization')"
      ],
      "metadata": {
        "id": "HvLfXEgh3Afb"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import numpy as np\n",
        "import os\n",
        "from omegaconf import OmegaConf\n",
        "from PIL import Image\n",
        "\n",
        "from utils.app_utils import (\n",
        "    remove_background,\n",
        "    resize_foreground,\n",
        "    set_white_background,\n",
        "    resize_to_128,\n",
        "    to_tensor,\n",
        "    get_source_camera_v2w_rmo_and_quats,\n",
        "    get_target_cameras,\n",
        "    export_to_obj\n",
        ")\n",
        "\n",
        "import imageio\n",
        "import rembg\n",
        "from huggingface_hub import hf_hub_download\n",
        "from scene.gaussian_predictor import GaussianSplatPredictor\n",
        "from scene.gaussian_predictor import GaussianSplatPredictor\n",
        "from gaussian_renderer import render_predicted"
      ],
      "metadata": {
        "id": "nEwg1KLux_xd"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## load model"
      ],
      "metadata": {
        "id": "mBgHX1c_uYcC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "# Load model configuration\n",
        "from omegaconf import OmegaConf\n",
        "import os\n",
        "\n",
        "# Specify the path directly\n",
        "config_path = \"/content/splatter-image/gradio_config.yaml\"  # Replace with the actual path\n",
        "model_cfg = OmegaConf.load(config_path)\n",
        "\n",
        "\n",
        "# Load pre-trained model weights\n",
        "model_path = hf_hub_download(repo_id=\"szymanowiczs/splatter-image-multi-category-v1\",\n",
        "                             filename=\"model_latest.pth\")\n",
        "model = GaussianSplatPredictor(model_cfg)\n",
        "ckpt_loaded = torch.load(model_path, map_location=\"cuda\")\n",
        "model.load_state_dict(ckpt_loaded[\"model_state_dict\"])\n",
        "model.to(\"cuda\")"
      ],
      "metadata": {
        "id": "qi3nGx9rzi3j"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inference"
      ],
      "metadata": {
        "id": "5nbyewL-t8wt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import rembg\n",
        "\n",
        "@torch.no_grad()\n",
        "def preprocess(input_image, preprocess_background=True, foreground_ratio=0.65):\n",
        "    # Create a new Rembg session\n",
        "    rembg_session = rembg.new_session()\n",
        "\n",
        "    # Preprocess input image\n",
        "    if preprocess_background:\n",
        "        image = input_image.convert(\"RGB\")\n",
        "        image = remove_background(image, rembg_session)\n",
        "        image = resize_foreground(image, foreground_ratio)\n",
        "        image = set_white_background(image)\n",
        "    else:\n",
        "        image = input_image\n",
        "        if image.mode == \"RGBA\":\n",
        "            image = set_white_background(image)\n",
        "\n",
        "    image = resize_to_128(image)\n",
        "\n",
        "    return image"
      ],
      "metadata": {
        "id": "ij7v3e1UzbcY"
      },
      "execution_count": 152,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def reconstruct_and_export_no_tensor(image, input_image_path):\n",
        "    \"\"\"\n",
        "    Passes image through model and outputs the reconstruction.\n",
        "    \"\"\"\n",
        "    device = \"cuda\"\n",
        "    view_to_world_source, rot_transform_quats = get_source_camera_v2w_rmo_and_quats()\n",
        "    view_to_world_source = view_to_world_source.to(device)\n",
        "    rot_transform_quats = rot_transform_quats.to(device)\n",
        "\n",
        "    reconstruction_unactivated = model(\n",
        "        image.unsqueeze(0).unsqueeze(0),\n",
        "        view_to_world_source,\n",
        "        rot_transform_quats,\n",
        "        None,\n",
        "        activate_output=False\n",
        "    )\n",
        "\n",
        "    reconstruction = {k: v[0].contiguous() for k, v in reconstruction_unactivated.items()}\n",
        "    reconstruction[\"scaling\"] = model.scaling_activation(reconstruction[\"scaling\"])\n",
        "    reconstruction[\"opacity\"] = model.opacity_activation(reconstruction[\"opacity\"])\n",
        "\n",
        "    # Render images in a loop\n",
        "    world_view_transforms, full_proj_transforms, camera_centers = get_target_cameras()\n",
        "    background = torch.tensor([1, 1, 1], dtype=torch.float32, device=device)\n",
        "    loop_renders = []\n",
        "    t_to_512 = torchvision.transforms.Resize(512, interpolation=torchvision.transforms.InterpolationMode.NEAREST)\n",
        "\n",
        "    for r_idx in range(world_view_transforms.shape[0]):\n",
        "        rendered_image = render_predicted(\n",
        "            reconstruction,\n",
        "            world_view_transforms[r_idx].to(device),\n",
        "            full_proj_transforms[r_idx].to(device),\n",
        "            camera_centers[r_idx].to(device),\n",
        "            background,\n",
        "            model_cfg,\n",
        "            focals_pixels=None\n",
        "        )[\"render\"]\n",
        "        rendered_image = t_to_512(rendered_image)\n",
        "        loop_renders.append(torch.clamp(rendered_image * 255, 0.0, 255.0).detach().permute(1, 2, 0).cpu().numpy().astype(np.uint8))\n",
        "\n",
        "    loop_out_path = f'./loop_{os.path.basename(input_image_path)}.mp4'\n",
        "    imageio.mimsave(\"/content/loop_.mp4\", loop_renders, fps=25)\n",
        "\n",
        "    # Export to .ply\n",
        "    ply_out_path = f'./mesh_{os.path.basename(input_image_path)}.ply'\n",
        "    export_to_obj(reconstruction_unactivated, \"/content/mesh.ply\")\n",
        "\n",
        "    return ply_out_path, loop_out_path"
      ],
      "metadata": {
        "id": "J4KiOia3tdyP"
      },
      "execution_count": 153,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 158,
      "metadata": {
        "id": "HeY4jzESxzG1"
      },
      "outputs": [],
      "source": [
        "import pprint\n",
        "\n",
        "def reconstruct_and_export(image, image_name):\n",
        "    \"\"\"\n",
        "    Passes image through model and outputs the reconstruction.\n",
        "    \"\"\"\n",
        "    device = \"cuda\"\n",
        "    image_tensor = to_tensor(image).to(device)\n",
        "    view_to_world_source, rot_transform_quats = get_source_camera_v2w_rmo_and_quats()\n",
        "    view_to_world_source = view_to_world_source.to(device)\n",
        "    rot_transform_quats = rot_transform_quats.to(device)\n",
        "\n",
        "    reconstruction_unactivated = model(\n",
        "        image_tensor.unsqueeze(0).unsqueeze(0),\n",
        "        view_to_world_source,\n",
        "        rot_transform_quats,\n",
        "        None,\n",
        "        activate_output=False\n",
        "    )\n",
        "\n",
        "\n",
        "    reconstruction = {k: v[0].contiguous() for k, v in reconstruction_unactivated.items()}\n",
        "    reconstruction[\"scaling\"] = model.scaling_activation(reconstruction[\"scaling\"])\n",
        "    reconstruction[\"opacity\"] = model.opacity_activation(reconstruction[\"opacity\"])\n",
        "\n",
        "    # Render images in a loop\n",
        "    world_view_transforms, full_proj_transforms, camera_centers = get_target_cameras()\n",
        "    background = torch.tensor([1, 1, 1], dtype=torch.float32, device=device)\n",
        "    loop_renders = []\n",
        "    t_to_512 = torchvision.transforms.Resize(512, interpolation=torchvision.transforms.InterpolationMode.NEAREST)\n",
        "\n",
        "    for r_idx in range(world_view_transforms.shape[0]):\n",
        "        rendered_image = render_predicted(\n",
        "            reconstruction,\n",
        "            world_view_transforms[r_idx].to(device),\n",
        "            full_proj_transforms[r_idx].to(device),\n",
        "            camera_centers[r_idx].to(device),\n",
        "            background,\n",
        "            model_cfg,\n",
        "            focals_pixels=None\n",
        "        )[\"render\"]\n",
        "        rendered_image = t_to_512(rendered_image)\n",
        "        loop_renders.append(torch.clamp(rendered_image * 255, 0.0, 255.0).detach().permute(1, 2, 0).cpu().numpy().astype(np.uint8))\n",
        "\n",
        "    imageio.mimsave(f\"{image_name}.mp4\", loop_renders, fps=25)\n",
        "\n",
        "    export_to_obj(reconstruction_unactivated, f\"{image_name}_mesh.ply\")\n",
        "\n",
        "    return ply_out_path, loop_out_path"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image = Image.open(\"/content/front.png\")\n",
        "\n",
        "process_image = preprocess(image, preprocess_background=False, foreground_ratio=0.65)\n",
        "\n",
        "# Perform reconstruction and export results\n",
        "ply_out_path, loop_out_path = reconstruct_and_export(np.array(process_image))\n",
        "\n",
        "print(f\"3D model saved to {ply_out_path}\")\n",
        "print(f\"Video render saved to {loop_out_path}\")"
      ],
      "metadata": {
        "id": "olpBfMe9zZNJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "def process_images_in_folder(folder_path):\n",
        "    for filename in os.listdir(folder_path):\n",
        "        if filename.lower().endswith(('.png', '.jpg', '.jpeg')):  # Check for image files\n",
        "            image_path = os.path.join(folder_path, filename)\n",
        "            print(f\"Processing image: {image_path}\")\n",
        "\n",
        "            image = Image.open(image_path)\n",
        "            process_image = preprocess(image, preprocess_background=False, foreground_ratio=0.65)\n",
        "\n",
        "            # Perform reconstruction and export results\n",
        "            ply_out_path, loop_out_path = reconstruct_and_export(np.array(process_image), image_path)\n",
        "\n",
        "            print(f\"3D model saved to {ply_out_path}\")\n",
        "            print(f\"Video render saved to {loop_out_path}\")\n",
        "\n",
        "# Usage\n",
        "folder_path = '/content/fused_image'\n",
        "process_images_in_folder(folder_path)"
      ],
      "metadata": {
        "id": "2bqhx-LPND75"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: zip folder\n",
        "\n",
        "!zip -r /content/fused_image.zip /content/fused_image"
      ],
      "metadata": {
        "id": "DpMl9Z8bXjsK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}